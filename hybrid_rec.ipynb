{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be89ec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain-Dependent Hybrid Recommender System\n",
      "\n",
      "Ready! Call run_menu() to start\n",
      "\n",
      "Domain-Dependent Hybrid Recommender\n",
      "==================================================\n",
      "1. Movies pipeline\n",
      "2. Books pipeline\n",
      "3. Cross-domain comparison\n",
      "4. Transfer learning\n",
      "0. Exit\n",
      "Transfer Learning Analysis\n",
      "========================================\n",
      "Loading movies dataset...\n",
      "Final: 108,005 ratings, 1,996 movies, 22,644 users\n",
      "Loading books dataset...\n",
      "Final: 52,045 ratings, 1,491 books, 13,915 users\n",
      "Creating realistic cross-domain overlap...\n",
      "  Threshold 3: Movies=22644, Books=13915\n",
      "Target overlap: 6957 users\n",
      "Created 6957 cross-domain users\n",
      "\n",
      "Training models...\n",
      "Training models for movies...\n",
      "Training SVD...\n",
      "Users: 22,571, Items: 1,994\n",
      "SVD training complete\n",
      "Training ItemCF...\n",
      "ItemCF training complete\n",
      "Training Content-based model...\n",
      "Created 17199 user profiles\n",
      "Training complete: 5 models\n",
      "Training models for books...\n",
      "Training SVD...\n",
      "Users: 13,852, Items: 1,500\n",
      "SVD training complete\n",
      "Training ItemCF...\n",
      "ItemCF training complete\n",
      "Training Content-based model...\n",
      "Created 9202 user profiles\n",
      "Training complete: 5 models\n",
      "\n",
      "Evaluating native performance on cross-domain users...\n",
      "Evaluating 5 models with 60 users...\n",
      "Testing svd_movies...\n",
      "Testing itemcf_movies...\n",
      "Testing content_movies...\n",
      "Testing itemcf_content_movies...\n",
      "Testing svd_itemcf_movies...\n",
      "Evaluating 5 models with 60 users...\n",
      "Testing svd_books...\n",
      "Testing itemcf_books...\n",
      "Testing content_books...\n",
      "Testing itemcf_content_books...\n",
      "Testing svd_itemcf_books...\n",
      "\n",
      "Evaluating transfer learning...\n",
      "Evaluating transfer learning (movies_to_books)...\n",
      "Evaluating with 6957 cross-domain users...\n",
      "  Transfer testing svd_movies...\n",
      "    svd_movies: 50 successful evaluations, P@10=0.048\n",
      "  Transfer testing itemcf_movies...\n",
      "    itemcf_movies: 50 successful evaluations, P@10=0.044\n",
      "  Transfer testing content_movies...\n",
      "    content_movies: 50 successful evaluations, P@10=0.076\n",
      "  Transfer testing itemcf_content_movies...\n",
      "    itemcf_content_movies: 50 successful evaluations, P@10=0.046\n",
      "  Transfer testing svd_itemcf_movies...\n",
      "    svd_itemcf_movies: 50 successful evaluations, P@10=0.048\n",
      "Evaluating transfer learning (books_to_movies)...\n",
      "Evaluating with 6957 cross-domain users...\n",
      "  Transfer testing svd_books...\n",
      "    svd_books: 50 successful evaluations, P@10=0.060\n",
      "  Transfer testing itemcf_books...\n",
      "    itemcf_books: 50 successful evaluations, P@10=0.066\n",
      "  Transfer testing content_books...\n",
      "    content_books: 50 successful evaluations, P@10=0.090\n",
      "  Transfer testing itemcf_content_books...\n",
      "    itemcf_content_books: 50 successful evaluations, P@10=0.068\n",
      "  Transfer testing svd_itemcf_books...\n",
      "    svd_itemcf_books: 50 successful evaluations, P@10=0.068\n",
      "\n",
      "======================================================================\n",
      "PROPER TRANSFER LEARNING RESULTS\n",
      "======================================================================\n",
      "\n",
      "MOVIES → BOOKS TRANSFER (Cross-Domain Users Only)\n",
      "Model                | Native   | Transfer | Retention  | Status    \n",
      "---------------------------------------------------------------------------\n",
      "svd                  | 0.156    | 0.048    | 30.8      % | ○ Weak    \n",
      "itemcf               | 0.198    | 0.044    | 22.3      % | ○ Weak    \n",
      "content              | 0.244    | 0.076    | 31.1      % | ○ Weak    \n",
      "itemcf_content       | 0.207    | 0.046    | 22.2      % | ○ Weak    \n",
      "svd_itemcf           | 0.186    | 0.048    | 25.8      % | ○ Weak    \n",
      "\n",
      "BOOKS → MOVIES TRANSFER (Cross-Domain Users Only)\n",
      "Model                | Native   | Transfer | Retention  | Status    \n",
      "---------------------------------------------------------------------------\n",
      "svd                  | 0.100    | 0.060    | 60.0      % | ✓ Good    \n",
      "itemcf               | 0.167    | 0.066    | 39.6      % | ○ Weak    \n",
      "content              | 0.300    | 0.090    | 30.0      % | ○ Weak    \n",
      "itemcf_content       | 0.300    | 0.068    | 22.7      % | ○ Weak    \n",
      "svd_itemcf           | 0.133    | 0.068    | 51.0      % | ✓ Good    \n",
      "\n",
      "TRANSFER QUALITY GUIDE:\n",
      "✓ Good transfer: 40-90% retention (learns transferable patterns)\n",
      "○ Weak transfer: 20-40% retention (some generalization)\n",
      "✗ Poor transfer: <20% retention (domain-specific learning)\n",
      "? Suspicious: >100% retention (check implementation)\n"
     ]
    }
   ],
   "source": [
    "# Domain-Dependent Hybrid Recommender System\n",
    "# @author Velizar Petrov\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transfer_learning import (\n",
    "    BidirectionalKnowledgeTransfer,\n",
    "    CrossDomainRecommender,\n",
    "    create_realistic_cross_domain_overlap,\n",
    "    evaluate_proper_transfer_fixed,\n",
    "    run_complete_transfer_analysis,\n",
    "    display_transfer_results)\n",
    "\n",
    "print(\"Domain-Dependent Hybrid Recommender System\")\n",
    "\n",
    "# CORE MODEL CLASSES \n",
    "\n",
    "class BiasedSVDRecommender:\n",
    "    # SVD with user and item bias terms added to base predictions\n",
    "    \n",
    "    def __init__(self, n_components=100):\n",
    "        self.n_components = n_components\n",
    "        self.user_factors = None\n",
    "        self.item_factors = None\n",
    "        self.user_biases = None\n",
    "        self.item_biases = None\n",
    "        self.global_mean = 0\n",
    "        self.user_mapper = {}\n",
    "        self.item_mapper = {}\n",
    "        \n",
    "    def fit(self, ratings_df):\n",
    "        print(f\"Training SVD...\")\n",
    "        self.global_mean = ratings_df['rating'].mean()\n",
    "        \n",
    "        # Create mappings from user/item IDs to matrix indices\n",
    "        unique_users = ratings_df['userId'].unique()\n",
    "        unique_items = ratings_df['movieId'].unique()\n",
    "        self.user_mapper = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.item_mapper = {item: idx for idx, item in enumerate(unique_items)}\n",
    "        \n",
    "        n_users, n_items = len(unique_users), len(unique_items)\n",
    "        print(f\"Users: {n_users:,}, Items: {n_items:,}\")\n",
    "        \n",
    "        # Build sparse user-item matrix, centered around global mean\n",
    "        user_indices = ratings_df['userId'].map(self.user_mapper).values\n",
    "        item_indices = ratings_df['movieId'].map(self.item_mapper).values\n",
    "        ratings = ratings_df['rating'].values\n",
    "        \n",
    "        rating_matrix = csr_matrix(\n",
    "            (ratings - self.global_mean, (user_indices, item_indices)),\n",
    "            shape=(n_users, n_items)\n",
    "        )\n",
    "        \n",
    "        # Decompose into user and item latent factors\n",
    "        svd = TruncatedSVD(n_components=self.n_components, random_state=42)\n",
    "        self.user_factors = svd.fit_transform(rating_matrix)\n",
    "        self.item_factors = svd.components_.T\n",
    "        \n",
    "        # Calculate bias terms by averaging residuals for each user/item\n",
    "        self.user_biases = np.zeros(n_users)\n",
    "        self.item_biases = np.zeros(n_items)\n",
    "        \n",
    "        for user_idx, item_idx, rating in zip(user_indices, item_indices, ratings):\n",
    "            prediction = np.dot(self.user_factors[user_idx], self.item_factors[item_idx])\n",
    "            error = rating - self.global_mean - prediction\n",
    "            self.user_biases[user_idx] += error\n",
    "            self.item_biases[item_idx] += error\n",
    "        \n",
    "        # Average the accumulated errors\n",
    "        user_counts = np.bincount(user_indices)\n",
    "        item_counts = np.bincount(item_indices)\n",
    "        \n",
    "        for user_idx in range(n_users):\n",
    "            if user_counts[user_idx] > 0:\n",
    "                self.user_biases[user_idx] /= user_counts[user_idx]\n",
    "        \n",
    "        for item_idx in range(n_items):\n",
    "            if item_counts[item_idx] > 0:\n",
    "                self.item_biases[item_idx] /= item_counts[item_idx]\n",
    "        \n",
    "        print(f\"SVD training complete\")\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        # Cold start: return global mean if user or item not seen during training\n",
    "        if user_id not in self.user_mapper or item_id not in self.item_mapper:\n",
    "            return self.global_mean\n",
    "        \n",
    "        user_idx = self.user_mapper[user_id]\n",
    "        item_idx = self.item_mapper[item_id]\n",
    "        \n",
    "        # Prediction = global mean + user bias + item bias + latent factor interaction\n",
    "        prediction = (self.global_mean + \n",
    "                     self.user_biases[user_idx] + \n",
    "                     self.item_biases[item_idx] + \n",
    "                     np.dot(self.user_factors[user_idx], self.item_factors[item_idx]))\n",
    "        \n",
    "        return max(1.0, min(5.0, prediction))\n",
    "\n",
    "\n",
    "class ItemBasedCF:\n",
    "    # Item-based collaborative filtering using cosine similarity\n",
    "    \n",
    "    def __init__(self, k=30):\n",
    "        self.k = k  # Number of similar items to use for prediction\n",
    "        self.item_similarity = None\n",
    "        self.ratings_matrix = None\n",
    "        self.user_mapper = {}\n",
    "        self.item_mapper = {}\n",
    "        self.global_mean = 0\n",
    "        self.item_means = {}\n",
    "        \n",
    "    def fit(self, ratings_df):\n",
    "        print(\"Training ItemCF...\")\n",
    "        \n",
    "        self.global_mean = ratings_df['rating'].mean()\n",
    "        item_stats = ratings_df.groupby('movieId')['rating'].mean()\n",
    "        self.item_means = item_stats.to_dict()\n",
    "        \n",
    "        # Limit to top 3000 items for computational efficiency\n",
    "        item_counts = ratings_df['movieId'].value_counts()\n",
    "        top_items = item_counts.head(3000).index\n",
    "        filtered_ratings = ratings_df[ratings_df['movieId'].isin(top_items)]\n",
    "        \n",
    "        unique_users = filtered_ratings['userId'].unique()\n",
    "        unique_items = filtered_ratings['movieId'].unique()\n",
    "        self.user_mapper = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.item_mapper = {item: idx for idx, item in enumerate(unique_items)}\n",
    "        \n",
    "        user_indices = filtered_ratings['userId'].map(self.user_mapper)\n",
    "        item_indices = filtered_ratings['movieId'].map(self.item_mapper)\n",
    "        \n",
    "        # Build user-item matrix and compute item-item similarity\n",
    "        self.ratings_matrix = csr_matrix(\n",
    "            (filtered_ratings['rating'], (user_indices, item_indices)),\n",
    "            shape=(len(unique_users), len(unique_items))\n",
    "        )\n",
    "        \n",
    "        self.item_similarity = cosine_similarity(self.ratings_matrix.T)\n",
    "        print(\"ItemCF training complete\")\n",
    "        \n",
    "    def predict(self, user_id, item_id):\n",
    "        item_mean = self.item_means.get(item_id, self.global_mean)\n",
    "        \n",
    "        # Cold start fallback\n",
    "        if user_id not in self.user_mapper or item_id not in self.item_mapper:\n",
    "            return item_mean\n",
    "        \n",
    "        user_idx = self.user_mapper[user_id]\n",
    "        item_idx = self.item_mapper[item_id]\n",
    "        \n",
    "        # Get this user's ratings and find similar items they've rated\n",
    "        user_ratings = self.ratings_matrix[user_idx].toarray().flatten()\n",
    "        similarities = self.item_similarity[item_idx]\n",
    "        rated_items = np.where(user_ratings > 0)[0]\n",
    "        \n",
    "        if len(rated_items) == 0:\n",
    "            return item_mean\n",
    "        \n",
    "        # Filter to sufficiently similar items and keep top k\n",
    "        similar_items = [(similarities[item], user_ratings[item]) \n",
    "                        for item in rated_items if similarities[item] > 0.05]\n",
    "        similar_items.sort(reverse=True)\n",
    "        similar_items = similar_items[:self.k]\n",
    "        \n",
    "        if not similar_items:\n",
    "            return item_mean\n",
    "        \n",
    "        # Weighted average of similar items' ratings\n",
    "        numerator = sum(sim * rating for sim, rating in similar_items)\n",
    "        denominator = sum(abs(sim) for sim, rating in similar_items)\n",
    "        \n",
    "        if denominator > 0:\n",
    "            return max(1.0, min(5.0, numerator / denominator))\n",
    "        \n",
    "        return item_mean\n",
    "\n",
    "\n",
    "class ContentBasedRecommender:\n",
    "    # Content-based filtering using TF-IDF representations of item metadata\n",
    "    \n",
    "    def __init__(self, max_features=5000):\n",
    "        self.max_features = max_features\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "        self.item_profiles = None\n",
    "        self.user_profiles = {}\n",
    "        self.item_mapper = {}\n",
    "        self.global_mean = 0\n",
    "        self.user_means = {}\n",
    "        \n",
    "    def fit(self, items_df, ratings_df):\n",
    "        print(\"Training Content-based model...\")\n",
    "        \n",
    "        self.global_mean = ratings_df['rating'].mean()\n",
    "        user_stats = ratings_df.groupby('userId')['rating'].mean()\n",
    "        self.user_means = user_stats.to_dict()\n",
    "        \n",
    "        # Create TF-IDF vectors from item content\n",
    "        content = items_df['content_features'].fillna('').astype(str)\n",
    "        self.item_profiles = self.vectorizer.fit_transform(content)\n",
    "        self.item_mapper = {item: idx for idx, item in enumerate(items_df['movieId'])}\n",
    "        \n",
    "        # Build user profiles as weighted combinations of items they rated highly\n",
    "        user_item_ratings = {}\n",
    "        for _, row in ratings_df.iterrows():\n",
    "            user_id = row['userId']\n",
    "            item_id = row['movieId']\n",
    "            rating = row['rating']\n",
    "            \n",
    "            if item_id in self.item_mapper:\n",
    "                if user_id not in user_item_ratings:\n",
    "                    user_item_ratings[user_id] = []\n",
    "                user_item_ratings[user_id].append((self.item_mapper[item_id], rating))\n",
    "        \n",
    "        # Only use above-average ratings to build preferences\n",
    "        for user_id, item_ratings in user_item_ratings.items():\n",
    "            if len(item_ratings) < 3:\n",
    "                continue\n",
    "            \n",
    "            user_mean = np.mean([rating for _, rating in item_ratings])\n",
    "            weighted_profile = None\n",
    "            total_weight = 0\n",
    "            \n",
    "            for item_idx, rating in item_ratings:\n",
    "                if rating >= user_mean:\n",
    "                    weight = rating - user_mean + 1\n",
    "                    item_profile = self.item_profiles[item_idx].toarray().flatten()\n",
    "                    \n",
    "                    if weighted_profile is None:\n",
    "                        weighted_profile = weight * item_profile\n",
    "                    else:\n",
    "                        weighted_profile += weight * item_profile\n",
    "                    total_weight += weight\n",
    "            \n",
    "            if total_weight > 0:\n",
    "                self.user_profiles[user_id] = weighted_profile / total_weight\n",
    "        \n",
    "        print(f\"Created {len(self.user_profiles)} user profiles\")\n",
    "        \n",
    "    def predict(self, user_id, item_id):\n",
    "        user_mean = self.user_means.get(user_id, self.global_mean)\n",
    "        \n",
    "        # Cold start fallback\n",
    "        if user_id not in self.user_profiles or item_id not in self.item_mapper:\n",
    "            return user_mean\n",
    "        \n",
    "        user_profile = self.user_profiles[user_id]\n",
    "        item_idx = self.item_mapper[item_id]\n",
    "        item_profile = self.item_profiles[item_idx].toarray().flatten()\n",
    "        \n",
    "        # Calculate cosine similarity between user and item profiles\n",
    "        try:\n",
    "            similarity = 1 - cosine(user_profile, item_profile)\n",
    "            similarity = max(0, min(1, similarity))\n",
    "        except:\n",
    "            similarity = 0.5\n",
    "        \n",
    "        # Simple threshold-based rating offset\n",
    "        if similarity > 0.6:\n",
    "            rating_offset = 1.0\n",
    "        elif similarity > 0.4:\n",
    "            rating_offset = 0.5\n",
    "        else:\n",
    "            rating_offset = 0.0\n",
    "        \n",
    "        return max(1.0, min(5.0, user_mean + rating_offset))\n",
    "\n",
    "\n",
    "class HybridRecommender:\n",
    "    # Simple weighted average hybrid of multiple models\n",
    "    \n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models  # List of (name, model) tuples\n",
    "        self.weights = weights or [1.0] * len(models)\n",
    "        \n",
    "    def predict(self, user_id, item_id):\n",
    "        predictions = []\n",
    "        weights = []\n",
    "        \n",
    "        # Collect predictions from all available models\n",
    "        for i, (name, model) in enumerate(self.models):\n",
    "            try:\n",
    "                pred = model.predict(user_id, item_id)\n",
    "                if not (np.isnan(pred) or np.isinf(pred)):\n",
    "                    predictions.append(pred)\n",
    "                    weights.append(self.weights[i])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not predictions:\n",
    "            return 3.0\n",
    "        \n",
    "        # Weighted average\n",
    "        if sum(weights) > 0:\n",
    "            return max(1.0, min(5.0, np.average(predictions, weights=weights)))\n",
    "        \n",
    "        return max(1.0, min(5.0, np.mean(predictions)))\n",
    "\n",
    "\n",
    "# DATA LOADING \n",
    "\n",
    "def load_dataset(dataset_type='movies', max_items=3000, max_ratings=300000):\n",
    "    #Load movies or books dataset\n",
    "    print(f\"Loading {dataset_type} dataset...\")\n",
    "    \n",
    "    if dataset_type == 'books':\n",
    "        return load_books_data(max_items, max_ratings)\n",
    "    else:\n",
    "        return load_movies_data(max_items, max_ratings)\n",
    "\n",
    "\n",
    "def load_movies_data(max_movies, max_ratings):\n",
    "    #Load movie dataset and combine content features\n",
    "    base_path = \"Datasets/The Movies Dataset\"\n",
    "    \n",
    "    movies = pd.read_csv(os.path.join(base_path, \"movies_clean.csv\"))\n",
    "    content_features = pd.read_csv(os.path.join(base_path, \"content_features.csv\"))\n",
    "    movies = movies.merge(content_features, on='id', how='left')\n",
    "    \n",
    "    # Combine all text fields into single content string\n",
    "    def combine_content(row):\n",
    "        parts = []\n",
    "        for field in ['genres', 'overview', 'tagline', 'content_features']:\n",
    "            if pd.notna(row.get(field)):\n",
    "                parts.append(str(row[field]))\n",
    "        return ' '.join(parts)\n",
    "    \n",
    "    movies['content_features'] = movies.apply(combine_content, axis=1)\n",
    "    \n",
    "    ratings = pd.read_csv(os.path.join(base_path, \"ratings_clean.csv\"))\n",
    "    \n",
    "    # Sample popular movies to limit dataset size\n",
    "    popular_movies = ratings['movieId'].value_counts().head(max_movies).index\n",
    "    movies = movies[movies['id'].isin(popular_movies)]\n",
    "    ratings = ratings[ratings['movieId'].isin(popular_movies)]\n",
    "    \n",
    "    if len(ratings) > max_ratings:\n",
    "        ratings = ratings.sample(n=max_ratings, random_state=42)\n",
    "    \n",
    "    movies = movies.rename(columns={'id': 'movieId'})\n",
    "    \n",
    "    # Filter out users and items with too few ratings\n",
    "    user_counts = ratings['userId'].value_counts()\n",
    "    item_counts = ratings['movieId'].value_counts()\n",
    "    valid_users = user_counts[user_counts >= 3].index\n",
    "    valid_items = item_counts[item_counts >= 3].index\n",
    "    \n",
    "    ratings = ratings[\n",
    "        (ratings['userId'].isin(valid_users)) & \n",
    "        (ratings['movieId'].isin(valid_items))\n",
    "    ]\n",
    "    \n",
    "    movies = movies[movies['movieId'].isin(ratings['movieId'].unique())]\n",
    "    \n",
    "    print(f\"Final: {len(ratings):,} ratings, {len(movies):,} movies, {len(ratings['userId'].unique()):,} users\")\n",
    "    return {'ratings': ratings, 'movies': movies}\n",
    "\n",
    "\n",
    "def load_books_data(max_books, max_ratings):\n",
    "    # Load books dataset and combine content features\n",
    "    base_path = \"Datasets/goodbooks_10k_rating_and_description\"\n",
    "    \n",
    "    books = pd.read_csv(os.path.join(base_path, \"goodbooks_10k_rating_and_description.csv\"))\n",
    "    \n",
    "    # Combine all book metadata into single content string\n",
    "    def combine_book_content(row):\n",
    "        parts = []\n",
    "        for field in ['genres', 'book_desc', 'title', 'book_authors', 'tags']:\n",
    "            if field in row.index and pd.notna(row.get(field)):\n",
    "                parts.append(str(row[field]))\n",
    "        return ' '.join(parts)\n",
    "    \n",
    "    books['content_features'] = books.apply(combine_book_content, axis=1)\n",
    "    \n",
    "    ratings = pd.read_csv(os.path.join(base_path, \"ratings.csv\"))\n",
    "    \n",
    "    # Standardize column names to match movies dataset\n",
    "    if 'user_id' in ratings.columns:\n",
    "        ratings = ratings.rename(columns={'user_id': 'userId'})\n",
    "    if 'book_id' in ratings.columns:\n",
    "        ratings = ratings.rename(columns={'book_id': 'movieId'})\n",
    "    \n",
    "    if len(ratings) > max_ratings:\n",
    "        ratings = ratings.sample(n=max_ratings, random_state=42)\n",
    "    \n",
    "    popular_books = ratings['movieId'].value_counts().head(max_books).index\n",
    "    \n",
    "    # Handle different possible book ID column names\n",
    "    if 'book_id' not in books.columns:\n",
    "        for col in ['id', 'bookId', 'book_ID']:\n",
    "            if col in books.columns:\n",
    "                books = books.rename(columns={col: 'book_id'})\n",
    "                break\n",
    "    \n",
    "    books = books[books['book_id'].isin(popular_books)]\n",
    "    ratings = ratings[ratings['movieId'].isin(popular_books)]\n",
    "    books = books.rename(columns={'book_id': 'movieId'})\n",
    "    \n",
    "    # Filter out sparse users/items\n",
    "    user_counts = ratings['userId'].value_counts()\n",
    "    item_counts = ratings['movieId'].value_counts()\n",
    "    valid_users = user_counts[user_counts >= 3].index\n",
    "    valid_items = item_counts[item_counts >= 3].index\n",
    "    \n",
    "    ratings = ratings[\n",
    "        (ratings['userId'].isin(valid_users)) & \n",
    "        (ratings['movieId'].isin(valid_items))\n",
    "    ]\n",
    "    \n",
    "    books = books[books['movieId'].isin(ratings['movieId'].unique())]\n",
    "    \n",
    "    print(f\"Final: {len(ratings):,} ratings, {len(books):,} books, {len(ratings['userId'].unique()):,} users\")\n",
    "    return {'ratings': ratings, 'movies': books}\n",
    "\n",
    "\n",
    "class BeyondAccuracyMetrics:\n",
    "    # Calculate novelty, diversity, and serendipity metrics\n",
    "    \n",
    "    def __init__(self, items_df, ratings_df):\n",
    "        self.items_df = items_df\n",
    "        self.item_popularity = ratings_df['movieId'].value_counts().to_dict()\n",
    "        self.total_ratings = len(ratings_df)\n",
    "        \n",
    "        # Precompute content similarity matrix for diversity calculations\n",
    "        content = items_df['content_features'].fillna('').astype(str)\n",
    "        vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "        content_matrix = vectorizer.fit_transform(content)\n",
    "        self.content_similarity = cosine_similarity(content_matrix)\n",
    "        self.item_to_idx = {item_id: idx for idx, item_id in enumerate(items_df['movieId'])}\n",
    "    \n",
    "    def novelty(self, recommended_items):\n",
    "        # Novelty = average inverse popularity (how obscure are the recommendations)\n",
    "        novelty_scores = []\n",
    "        for item_id, _ in recommended_items:\n",
    "            pop = self.item_popularity.get(item_id, 1)\n",
    "            prob = pop / self.total_ratings\n",
    "            novelty_scores.append(-np.log(max(prob, 1e-10)))\n",
    "        return np.mean(novelty_scores) if novelty_scores else 0.0\n",
    "    \n",
    "    def diversity(self, recommended_items):\n",
    "        # Diversity = 1 - average pairwise similarity (how different recommendations are from each other)\n",
    "        item_ids = [item_id for item_id, _ in recommended_items]\n",
    "        valid_items = [item for item in item_ids if item in self.item_to_idx]\n",
    "        \n",
    "        if len(valid_items) < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        similarities = []\n",
    "        for i in range(len(valid_items)):\n",
    "            for j in range(i + 1, len(valid_items)):\n",
    "                idx_i = self.item_to_idx[valid_items[i]]\n",
    "                idx_j = self.item_to_idx[valid_items[j]]\n",
    "                similarities.append(self.content_similarity[idx_i, idx_j])\n",
    "        \n",
    "        return 1.0 - np.mean(similarities) if similarities else 0.0\n",
    "    \n",
    "    def serendipity(self, user_id, recommended_items, user_history):\n",
    "        # Serendipity = unexpectedness × relevance (surprising but good recommendations)\n",
    "        serendipity_scores = []\n",
    "        \n",
    "        for item_id, predicted_rating in recommended_items:\n",
    "            if item_id not in self.item_to_idx:\n",
    "                continue\n",
    "            \n",
    "            item_idx = self.item_to_idx[item_id]\n",
    "            \n",
    "            # Unexpectedness = how different is this from what user has seen\n",
    "            max_similarity = 0.0\n",
    "            for hist_item in user_history:\n",
    "                if hist_item in self.item_to_idx:\n",
    "                    hist_idx = self.item_to_idx[hist_item]\n",
    "                    similarity = self.content_similarity[item_idx, hist_idx]\n",
    "                    max_similarity = max(max_similarity, similarity)\n",
    "            \n",
    "            unexpectedness = 1.0 - max_similarity\n",
    "            # Relevance = predicted rating quality (normalized to 0-1)\n",
    "            relevance = max(0, (predicted_rating - 1.0) / 4.0)\n",
    "            serendipity_scores.append(unexpectedness * relevance)\n",
    "        \n",
    "        return np.mean(serendipity_scores) if serendipity_scores else 0.0\n",
    "\n",
    "\n",
    "# MODEL TRAINING \n",
    "\n",
    "def train_models(data_dict, dataset_type='movies'):\n",
    "    # Train all models for given dataset\n",
    "    print(f\"Training models for {dataset_type}...\")\n",
    "    \n",
    "    ratings_df = data_dict['ratings']\n",
    "    items_df = data_dict['movies']\n",
    "    \n",
    "    # 80/20 train/validation split\n",
    "    train_ratings, val_ratings = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    # Train SVD\n",
    "    try:\n",
    "        svd = BiasedSVDRecommender(n_components=200)\n",
    "        svd.fit(train_ratings)\n",
    "        models[f'svd_{dataset_type}'] = svd\n",
    "    except Exception as e:\n",
    "        print(f\"SVD failed: {e}\")\n",
    "    \n",
    "    # Train ItemCF\n",
    "    try:\n",
    "        itemcf = ItemBasedCF(k=50)\n",
    "        itemcf.fit(train_ratings)\n",
    "        models[f'itemcf_{dataset_type}'] = itemcf\n",
    "    except Exception as e:\n",
    "        print(f\"ItemCF failed: {e}\")\n",
    "    \n",
    "    # Train Content\n",
    "    try:\n",
    "        content = ContentBasedRecommender()\n",
    "        content.fit(items_df, train_ratings)\n",
    "        models[f'content_{dataset_type}'] = content\n",
    "    except Exception as e:\n",
    "        print(f\"Content failed: {e}\")\n",
    "    \n",
    "    # Train hybrids only if base models succeeded\n",
    "    # ItemCF+Content hybrid: 70% weight to content (it performs better)\n",
    "    if f'itemcf_{dataset_type}' in models and f'content_{dataset_type}' in models:\n",
    "        models[f'itemcf_content_{dataset_type}'] = HybridRecommender([\n",
    "            ('itemcf', models[f'itemcf_{dataset_type}']), \n",
    "            ('content', models[f'content_{dataset_type}'])\n",
    "        ], [0.3, 0.7])\n",
    "    \n",
    "    # SVD+ItemCF hybrid\n",
    "    if f'svd_{dataset_type}' in models and f'itemcf_{dataset_type}' in models:\n",
    "        models[f'svd_itemcf_{dataset_type}'] = HybridRecommender([\n",
    "            ('svd', models[f'svd_{dataset_type}']), \n",
    "            ('itemcf', models[f'itemcf_{dataset_type}'])\n",
    "        ], [0.3, 0.7])\n",
    "    \n",
    "    print(f\"Training complete: {len(models)} models\")\n",
    "    return models\n",
    "\n",
    "# THESIS PLOTS \n",
    "\n",
    "def create_thesis_plots(movies_results, books_results):\n",
    "    # Create 2x2 subplot figure for the paper\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Cross-Domain Recommendation Performance Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    models = ['SVD', 'ItemCF', 'Content', 'ItemCF+\\nContent', 'SVD+\\nItemCF']\n",
    "    \n",
    "    movies_p10 = [\n",
    "        movies_results.get('svd_movies', {}).get('precision@10', 0),\n",
    "        movies_results.get('itemcf_movies', {}).get('precision@10', 0),\n",
    "        movies_results.get('content_movies', {}).get('precision@10', 0),\n",
    "        movies_results.get('itemcf_content_movies', {}).get('precision@10', 0),\n",
    "        movies_results.get('svd_itemcf_movies', {}).get('precision@10', 0)\n",
    "    ]\n",
    "    \n",
    "    books_p10 = [\n",
    "        books_results.get('svd_books', {}).get('precision@10', 0),\n",
    "        books_results.get('itemcf_books', {}).get('precision@10', 0),\n",
    "        books_results.get('content_books', {}).get('precision@10', 0),\n",
    "        books_results.get('itemcf_content_books', {}).get('precision@10', 0),\n",
    "        books_results.get('svd_itemcf_books', {}).get('precision@10', 0)\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, movies_p10, width, label='Movies', color='steelblue', alpha=0.8)\n",
    "    bars2 = ax1.bar(x + width/2, books_p10, width, label='Books', color='coral', alpha=0.8)\n",
    "    \n",
    "    ax1.set_ylabel('Precision@10', fontsize=11)\n",
    "    ax1.set_title('Model Performance by Domain', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(models, fontsize=9)\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1%}', ha='center', va='bottom', fontsize=8)\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1%}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    movies_rmse = [\n",
    "        movies_results.get('svd_movies', {}).get('rmse', 0),\n",
    "        movies_results.get('itemcf_movies', {}).get('rmse', 0),\n",
    "        movies_results.get('content_movies', {}).get('rmse', 0),\n",
    "        movies_results.get('itemcf_content_movies', {}).get('rmse', 0),\n",
    "        movies_results.get('svd_itemcf_movies', {}).get('rmse', 0)\n",
    "    ]\n",
    "    \n",
    "    books_rmse = [\n",
    "        books_results.get('svd_books', {}).get('rmse', 0),\n",
    "        books_results.get('itemcf_books', {}).get('rmse', 0),\n",
    "        books_results.get('content_books', {}).get('rmse', 0),\n",
    "        books_results.get('itemcf_content_books', {}).get('rmse', 0),\n",
    "        books_results.get('svd_itemcf_books', {}).get('rmse', 0)\n",
    "    ]\n",
    "    \n",
    "    bars3 = ax2.bar(x - width/2, movies_rmse, width, label='Movies', color='steelblue', alpha=0.8)\n",
    "    bars4 = ax2.bar(x + width/2, books_rmse, width, label='Books', color='coral', alpha=0.8)\n",
    "    \n",
    "    ax2.set_ylabel('RMSE (lower is better)', fontsize=11)\n",
    "    ax2.set_title('Rating Prediction Accuracy', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(models, fontsize=9)\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    # Calculate books advantage (positive = books better, negative = movies better)\n",
    "    advantages = [books_p10[i] - movies_p10[i] for i in range(len(models))]\n",
    "    colors = ['green' if adv > 0 else 'red' for adv in advantages]\n",
    "    \n",
    "    bars5 = ax3.barh(models, advantages, color=colors, alpha=0.7)\n",
    "    ax3.set_xlabel('Books Advantage (Books P@10 - Movies P@10)', fontsize=11)\n",
    "    ax3.set_title('Domain-Specific Performance Differences', fontsize=12, fontweight='bold')\n",
    "    ax3.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    for i, (bar, value) in enumerate(zip(bars5, advantages)):\n",
    "        ax3.text(value + (0.005 if value >= 0 else -0.005), i,\n",
    "                f'{value:+.1%}', ha='left' if value >= 0 else 'right', \n",
    "                va='center', fontsize=9)\n",
    "    \n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    categories = ['Individual\\n(Best)', 'Hybrid\\n(Best)', 'CF\\n(Best)']\n",
    "    \n",
    "    # Compare best in each category\n",
    "    movies_cat = [\n",
    "        max(movies_p10[0], movies_p10[1], movies_p10[2]),\n",
    "        max(movies_p10[3], movies_p10[4]),\n",
    "        max(movies_p10[0], movies_p10[1])]\n",
    "    books_cat = [\n",
    "            max(books_p10[0], books_p10[1], books_p10[2]),\n",
    "            max(books_p10[3], books_p10[4]),\n",
    "            max(books_p10[0], books_p10[1])]\n",
    "    \n",
    "    x_cat = np.arange(len(categories))\n",
    "    \n",
    "    bars6 = ax4.bar(x_cat - width/2, movies_cat, width, label='Movies', color='steelblue', alpha=0.8)\n",
    "    bars7 = ax4.bar(x_cat + width/2, books_cat, width, label='Books', color='coral', alpha=0.8)\n",
    "    \n",
    "    ax4.set_ylabel('Best Precision@10', fontsize=11)\n",
    "    ax4.set_title('Best Performance by Model Category', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xticks(x_cat)\n",
    "    ax4.set_xticklabels(categories, fontsize=9)\n",
    "    ax4.legend(fontsize=10)\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar in bars6:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1%}', ha='center', va='bottom', fontsize=8)\n",
    "    for bar in bars7:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1%}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('thesis_results.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nPlot saved as 'thesis_results.png'\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_simple_comparison_plot(movies_results, books_results):\n",
    "    # Create single-plot comparison for the paper\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Order by performance for better visualisation\n",
    "    models = ['Content', 'ItemCF+Content', 'ItemCF', 'SVD+ItemCF', 'SVD']\n",
    "    \n",
    "    movies_p10 = [\n",
    "        movies_results.get('content_movies', {}).get('precision@10', 0),\n",
    "        movies_results.get('itemcf_content_movies', {}).get('precision@10', 0),\n",
    "        movies_results.get('itemcf_movies', {}).get('precision@10', 0),\n",
    "        movies_results.get('svd_itemcf_movies', {}).get('precision@10', 0),\n",
    "        movies_results.get('svd_movies', {}).get('precision@10', 0)\n",
    "    ]\n",
    "    \n",
    "    books_p10 = [\n",
    "        books_results.get('content_books', {}).get('precision@10', 0),\n",
    "        books_results.get('itemcf_content_books', {}).get('precision@10', 0),\n",
    "        books_results.get('itemcf_books', {}).get('precision@10', 0),\n",
    "        books_results.get('svd_itemcf_books', {}).get('precision@10', 0),\n",
    "        books_results.get('svd_books', {}).get('precision@10', 0)\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, movies_p10, width, label='Movies Domain', color='#2E86AB', alpha=0.85)\n",
    "    ax.bar(x + width/2, books_p10, width, label='Books Domain', color='#A23B72', alpha=0.85)\n",
    "    \n",
    "    ax.set_ylabel('Precision@10', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Recommendation Model', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Cross-Domain Recommendation Performance', fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, fontsize=11)\n",
    "    ax.legend(fontsize=12, loc='upper right')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('thesis_simple_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nSimple plot saved as 'thesis_simple_comparison.png'\")\n",
    "    plt.show()\n",
    "\n",
    "# EVALUATION \n",
    "\n",
    "def precision_at_k(y_true, y_pred, k=10, threshold=4.0):\n",
    "    # Precision@k: fraction of top-k recommendations that are relevant\n",
    "    top_k_indices = np.argsort(y_pred)[::-1][:k]\n",
    "    relevant_in_topk = sum(1 for idx in top_k_indices if y_true[idx] >= threshold)\n",
    "    return relevant_in_topk / k\n",
    "\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k=10, threshold=4.0):\n",
    "    # Recall@k: fraction of all relevant items found in top-k\n",
    "    relevant_items = sum(1 for rating in y_true if rating >= threshold)\n",
    "    if relevant_items == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    top_k_indices = np.argsort(y_pred)[::-1][:k]\n",
    "    relevant_in_topk = sum(1 for idx in top_k_indices if y_true[idx] >= threshold)\n",
    "    return relevant_in_topk / relevant_items\n",
    "\n",
    "\n",
    "def evaluate_models(models, train_data, test_data, items_df, sample_size=200):\n",
    "    # Evaluate all models with accuracy and beyond-accuracy metrics\n",
    "    print(f\"Evaluating {len(models)} models with {sample_size} users...\")\n",
    "    \n",
    "    beyond_metrics = BeyondAccuracyMetrics(items_df, train_data)\n",
    "    \n",
    "    results = {}\n",
    "    test_users = test_data['userId'].unique()\n",
    "    user_test_counts = test_data['userId'].value_counts()\n",
    "    # Only use users with sufficient test ratings\n",
    "    valid_users = user_test_counts[user_test_counts >= 5].index\n",
    "    \n",
    "    if len(valid_users) > sample_size:\n",
    "        sample_users = np.random.choice(valid_users, size=sample_size, replace=False)\n",
    "    else:\n",
    "        sample_users = valid_users\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Testing {model_name}...\")\n",
    "        \n",
    "        rmse_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        novelty_scores = []\n",
    "        diversity_scores = []\n",
    "        serendipity_scores = []\n",
    "        \n",
    "        for user_id in sample_users:\n",
    "            user_test = test_data[test_data['userId'] == user_id]\n",
    "            \n",
    "            if len(user_test) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Rating prediction evaluation\n",
    "            predictions = []\n",
    "            actuals = []\n",
    "            \n",
    "            for _, row in user_test.iterrows():\n",
    "                try:\n",
    "                    pred = model.predict(row['userId'], row['movieId'])\n",
    "                    if not (np.isnan(pred) or np.isinf(pred)):\n",
    "                        predictions.append(pred)\n",
    "                        actuals.append(row['rating'])\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if len(predictions) >= 3:\n",
    "                rmse_scores.append(np.sqrt(np.mean((np.array(actuals) - np.array(predictions)) ** 2)))\n",
    "            \n",
    "            # Ranking evaluation: mix test items with random candidates\n",
    "            user_seen = set(train_data[train_data['userId'] == user_id]['movieId'])\n",
    "            candidates = [item for item in items_df['movieId'].unique() if item not in user_seen]\n",
    "            \n",
    "            if len(candidates) < 30:\n",
    "                continue\n",
    "            \n",
    "            # Sample negative candidates (items user hasn't seen)\n",
    "            test_candidates = np.random.choice(candidates, size=min(50, len(candidates)), replace=False)\n",
    "            test_items = user_test['movieId'].tolist()\n",
    "            \n",
    "            # Combine for ranking task\n",
    "            eval_items = list(test_candidates) + test_items\n",
    "            eval_predictions = []\n",
    "            eval_actuals = []\n",
    "            \n",
    "            for item_id in eval_items:\n",
    "                try:\n",
    "                    pred = model.predict(user_id, item_id)\n",
    "                    eval_predictions.append(pred if not (np.isnan(pred) or np.isinf(pred)) else 3.0)\n",
    "                    \n",
    "                    if item_id in test_items:\n",
    "                        actual_rating = user_test[user_test['movieId'] == item_id]['rating'].iloc[0]\n",
    "                        eval_actuals.append(actual_rating)\n",
    "                    else:\n",
    "                        # Assume unrated items are not relevant\n",
    "                        eval_actuals.append(2.5)\n",
    "                except:\n",
    "                    eval_predictions.append(3.0)\n",
    "                    eval_actuals.append(2.5)\n",
    "            \n",
    "            if len(eval_predictions) >= 10:\n",
    "                precision_scores.append(precision_at_k(np.array(eval_actuals), np.array(eval_predictions), 10))\n",
    "                recall_scores.append(recall_at_k(np.array(eval_actuals), np.array(eval_predictions), 10))\n",
    "            \n",
    "            # Beyond-accuracy metrics: generate top-10 recommendations\n",
    "            try:\n",
    "                item_scores = []\n",
    "                # Limit to 100 candidates for efficiency\n",
    "                for item_id in candidates[:100]:\n",
    "                    try:\n",
    "                        score = model.predict(user_id, item_id)\n",
    "                        item_scores.append((item_id, score))\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                recommendations = sorted(item_scores, key=lambda x: x[1], reverse=True)[:10]\n",
    "                \n",
    "                if len(recommendations) >= 5:\n",
    "                    user_history = list(user_seen)\n",
    "                    novelty_scores.append(beyond_metrics.novelty(recommendations))\n",
    "                    diversity_scores.append(beyond_metrics.diversity(recommendations))\n",
    "                    serendipity_scores.append(beyond_metrics.serendipity(user_id, recommendations, user_history))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'rmse': np.mean(rmse_scores) if rmse_scores else float('inf'),\n",
    "            'precision@10': np.mean(precision_scores) if precision_scores else 0.0,\n",
    "            'recall@10': np.mean(recall_scores) if recall_scores else 0.0,\n",
    "            'novelty': np.mean(novelty_scores) if novelty_scores else 0.0,\n",
    "            'diversity': np.mean(diversity_scores) if diversity_scores else 0.0,\n",
    "            'serendipity': np.mean(serendipity_scores) if serendipity_scores else 0.0,\n",
    "            'users_tested': len(rmse_scores)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def display_results(results, title=\"Results\"):\n",
    "    # Display evaluation results table\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"{'Model':<25} | {'RMSE':<8} | {'Prec@10':<8} | {'Rec@10':<8} | {'Novelty':<7} | {'Diversity':<7} | {'Serendipity':<7}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Sort by precision@10 for easier comparison\n",
    "    sorted_models = sorted(results.items(), key=lambda x: x[1]['precision@10'], reverse=True)\n",
    "    \n",
    "    for model_name, metrics in sorted_models:\n",
    "        rmse = metrics['rmse']\n",
    "        rmse_str = f\"{rmse:.3f}\" if rmse != float('inf') else \"N/A\"\n",
    "        \n",
    "        print(f\"{model_name:<25} | {rmse_str:<8} | {metrics['precision@10']:<8.3f} | \"\n",
    "              f\"{metrics['recall@10']:<8.3f} | {metrics['novelty']:<7.2f} | \"\n",
    "              f\"{metrics['diversity']:<7.3f} | {metrics['serendipity']:<7.3f}\")\n",
    "\n",
    "\n",
    "# TRANSFER LEARNING \n",
    "\n",
    "def run_transfer_learning():\n",
    "    # Run complete transfer learning analysis\n",
    "    print(\"Transfer Learning Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Load both domains\n",
    "    movies_data = load_dataset('movies', max_items=2000, max_ratings=200000)\n",
    "    books_data = load_dataset('books', max_items=1500, max_ratings=150000)\n",
    "    \n",
    "    # Create simulated cross-domain user overlap\n",
    "    movies_transfer, books_transfer = create_realistic_cross_domain_overlap(\n",
    "        movies_data, books_data, min_overlap_users=100\n",
    "    )\n",
    "    \n",
    "    # Train models on both domains\n",
    "    print(\"\\nTraining models...\")\n",
    "    movies_models = train_models(movies_transfer, 'movies')\n",
    "    books_models = train_models(books_transfer, 'books')\n",
    "    \n",
    "    # Evaluate native performance on cross-domain users only\n",
    "    print(\"\\nEvaluating native performance on cross-domain users...\")\n",
    "    movies_cross_ratings = movies_transfer['ratings'][\n",
    "        movies_transfer['ratings']['userId'].isin(movies_transfer['cross_domain_users'])\n",
    "    ]\n",
    "    books_cross_ratings = books_transfer['ratings'][\n",
    "        books_transfer['ratings']['userId'].isin(books_transfer['cross_domain_users'])\n",
    "    ]\n",
    "    \n",
    "    movies_train, movies_test = train_test_split(movies_cross_ratings, test_size=0.2, random_state=42)\n",
    "    books_train, books_test = train_test_split(books_cross_ratings, test_size=0.2, random_state=42)\n",
    "    \n",
    "    movies_native = evaluate_models(movies_models, movies_train, movies_test, movies_transfer['movies'], 60)\n",
    "    books_native = evaluate_models(books_models, books_train, books_test, books_transfer['movies'], 60)\n",
    "    \n",
    "    # Evaluate transfer: apply source domain models to target domain\n",
    "    print(\"\\nEvaluating transfer learning...\")\n",
    "    movies_to_books = evaluate_proper_transfer_fixed(\n",
    "        movies_models, movies_transfer, books_transfer, 'movies_to_books', precision_at_k\n",
    "    )\n",
    "    books_to_movies = evaluate_proper_transfer_fixed(\n",
    "        books_models, books_transfer, movies_transfer, 'books_to_movies', precision_at_k\n",
    "    )\n",
    "    \n",
    "    # Display transfer results with retention percentages\n",
    "    display_transfer_results(movies_native, books_native, movies_to_books, books_to_movies)\n",
    "    \n",
    "    return {\n",
    "        'movies_native': movies_native,\n",
    "        'books_native': books_native,\n",
    "        'movies_to_books': movies_to_books,\n",
    "        'books_to_movies': books_to_movies\n",
    "    }\n",
    "\n",
    "\n",
    "# MAIN PIPELINE \n",
    "\n",
    "def run_complete_pipeline(dataset_type='movies'):\n",
    "    # Run complete training and evaluation pipeline for one dataset\n",
    "    print(f\"Running pipeline for {dataset_type}...\")\n",
    "    \n",
    "    # Load data\n",
    "    data_dict = load_dataset(dataset_type, max_items=3000, max_ratings=300000)\n",
    "    \n",
    "    # Train all models\n",
    "    models = train_models(data_dict, dataset_type)\n",
    "    \n",
    "    # Save trained models for later use (commented out for space preservation)\n",
    "    # os.makedirs(\"Models\", exist_ok=True)\n",
    "    # with open(f\"Models/models_{dataset_type}.pkl\", 'wb') as f:\n",
    "        # pickle.dump(models, f)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    train_data, test_data = train_test_split(data_dict['ratings'], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Sanity check: print single prediction from each model\n",
    "    print(\"\\nModel Prediction Sanity Check:\")\n",
    "    test_user = test_data['userId'].iloc[0]\n",
    "    test_item = test_data['movieId'].iloc[0]\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            pred = model.predict(test_user, test_item)\n",
    "            print(f\"{name}: {pred:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{name}: ERROR - {e}\")\n",
    "    \n",
    "    results = evaluate_models(models, train_data, test_data, data_dict['movies'])\n",
    "    \n",
    "    # Display results\n",
    "    display_results(results, f\"{dataset_type.title()} Results\")\n",
    "    \n",
    "    return models, results\n",
    "\n",
    "\n",
    "def run_cross_domain_comparison():\n",
    "    #Compare performance across movies and books domains\n",
    "    print(\"Cross-Domain Comparison\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Run full pipeline for both domains\n",
    "    movies_models, movies_results = run_complete_pipeline('movies')\n",
    "    books_models, books_results = run_complete_pipeline('books')\n",
    "    \n",
    "    # Find best model in each domain\n",
    "    movies_best = max(movies_results.items(), key=lambda x: x[1]['precision@10'])\n",
    "    books_best = max(books_results.items(), key=lambda x: x[1]['precision@10'])\n",
    "    \n",
    "    print(f\"\\nBEST MODELS:\")\n",
    "    print(f\"Movies: {movies_best[0]} (P@10: {movies_best[1]['precision@10']:.3f})\")\n",
    "    print(f\"Books:  {books_best[0]} (P@10: {books_best[1]['precision@10']:.3f})\")\n",
    "    \n",
    "    # Generate plots for the paper\n",
    "    print(\"\\nGenerating plots...\")\n",
    "    create_thesis_plots(movies_results, books_results)\n",
    "    create_simple_comparison_plot(movies_results, books_results)\n",
    "    \n",
    "    return {'movies': movies_results, 'books': books_results}\n",
    "\n",
    "\n",
    "# SIMPLE MENU \n",
    "\n",
    "def run_menu():\n",
    "    # Interactive menu for running different experiments\n",
    "    print(\"\\nDomain-Dependent Hybrid Recommender\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1. Movies pipeline\")\n",
    "    print(\"2. Books pipeline\")\n",
    "    print(\"3. Cross-domain comparison\")\n",
    "    print(\"4. Transfer learning\")\n",
    "    print(\"0. Exit\")\n",
    "    \n",
    "    choice = input(\"\\nChoice: \").strip()\n",
    "    \n",
    "    if choice == '1':\n",
    "        return run_complete_pipeline('movies')\n",
    "    elif choice == '2':\n",
    "        return run_complete_pipeline('books')\n",
    "    elif choice == '3':\n",
    "        return run_cross_domain_comparison()\n",
    "    elif choice == '4':\n",
    "        return run_transfer_learning()\n",
    "    elif choice == '0':\n",
    "        print(\"Done!\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"Invalid choice\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nReady! Call run_menu() to start\")\n",
    "    run_menu()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba2d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Domain-Dependent Hybrid Recommender\n",
      "==================================================\n",
      "1. Movies pipeline\n",
      "2. Books pipeline\n",
      "3. Cross-domain comparison\n",
      "4. Transfer learning\n",
      "0. Exit\n",
      "Running pipeline for books...\n",
      "Loading books dataset...\n",
      "Final: 210,863 ratings, 2,980 books, 40,079 users\n",
      "Training models for books...\n",
      "Training SVD...\n",
      "Users: 39,993, Items: 3,000\n",
      "SVD training complete\n",
      "Training ItemCF...\n",
      "ItemCF training complete\n",
      "Training Content-based model...\n",
      "Created 33496 user profiles\n",
      "Training complete: 5 models\n",
      "\n",
      "Model Prediction Sanity Check:\n",
      "svd_books: 4.119\n",
      "itemcf_books: 4.000\n",
      "content_books: 4.000\n",
      "itemcf_content_books: 4.000\n",
      "svd_itemcf_books: 4.036\n",
      "Evaluating 5 models with 200 users...\n",
      "Testing svd_books...\n",
      "Testing itemcf_books...\n",
      "Testing content_books...\n",
      "Testing itemcf_content_books...\n",
      "Testing svd_itemcf_books...\n",
      "\n",
      "Books Results\n",
      "====================================================================================================\n",
      "Model                     | RMSE     | P@10     | R@10     | Novel   | Divers  | Serend \n",
      "----------------------------------------------------------------------------------------------------\n",
      "content_books             | 0.927    | 0.322    | 0.916    | 5.79    | 0.619   | 0.398  \n",
      "itemcf_content_books      | 0.883    | 0.115    | 0.313    | 5.97    | 0.553   | 0.438  \n",
      "itemcf_books              | 0.919    | 0.095    | 0.260    | 5.91    | 0.558   | 0.570  \n",
      "svd_itemcf_books          | 0.895    | 0.075    | 0.202    | 5.91    | 0.557   | 0.541  \n",
      "svd_books                 | 0.930    | 0.058    | 0.155    | 6.55    | 0.752   | 0.479  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'svd_books': <__main__.ImprovedSVDRecommender at 0x19878aad000>,\n",
       "  'itemcf_books': <__main__.ItemBasedCF at 0x19878aacf70>,\n",
       "  'content_books': <__main__.ContentBasedRecommender at 0x19878aada80>,\n",
       "  'itemcf_content_books': <__main__.HybridRecommender at 0x19878aaed70>,\n",
       "  'svd_itemcf_books': <__main__.HybridRecommender at 0x19878aafac0>},\n",
       " {'svd_books': {'rmse': np.float64(0.9299164993938026),\n",
       "   'precision@10': np.float64(0.058024691358024696),\n",
       "   'recall@10': np.float64(0.15462962962962964),\n",
       "   'novelty': np.float64(6.547748831576749),\n",
       "   'diversity': np.float64(0.7515024786421108),\n",
       "   'serendipity': np.float64(0.47863696897348773),\n",
       "   'users_tested': 162},\n",
       "  'itemcf_books': {'rmse': np.float64(0.9186402612359683),\n",
       "   'precision@10': np.float64(0.09506172839506172),\n",
       "   'recall@10': np.float64(0.2598765432098765),\n",
       "   'novelty': np.float64(5.914783038518696),\n",
       "   'diversity': np.float64(0.5579211387065663),\n",
       "   'serendipity': np.float64(0.5696180151738128),\n",
       "   'users_tested': 162},\n",
       "  'content_books': {'rmse': np.float64(0.9273373105968188),\n",
       "   'precision@10': np.float64(0.3216049382716049),\n",
       "   'recall@10': np.float64(0.915843621399177),\n",
       "   'novelty': np.float64(5.786733081481256),\n",
       "   'diversity': np.float64(0.6191477936421214),\n",
       "   'serendipity': np.float64(0.39843452958956926),\n",
       "   'users_tested': 162},\n",
       "  'itemcf_content_books': {'rmse': np.float64(0.8826633999221675),\n",
       "   'precision@10': np.float64(0.11481481481481483),\n",
       "   'recall@10': np.float64(0.3131687242798354),\n",
       "   'novelty': np.float64(5.9653331350491605),\n",
       "   'diversity': np.float64(0.5532738645686319),\n",
       "   'serendipity': np.float64(0.43844268628923605),\n",
       "   'users_tested': 162},\n",
       "  'svd_itemcf_books': {'rmse': np.float64(0.8945958767053716),\n",
       "   'precision@10': np.float64(0.07469135802469136),\n",
       "   'recall@10': np.float64(0.2023809523809524),\n",
       "   'novelty': np.float64(5.912529342047789),\n",
       "   'diversity': np.float64(0.5568514967202014),\n",
       "   'serendipity': np.float64(0.54131306023624),\n",
       "   'users_tested': 162}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_menu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
